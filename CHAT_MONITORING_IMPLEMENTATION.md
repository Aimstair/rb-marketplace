# Chat Monitoring System - Implementation Guide

## ‚úÖ Completed Features

### 1. **Basic Chat Monitoring** (DONE)
- ‚úÖ Real-time conversation list with participants
- ‚úÖ Full message history viewing
- ‚úÖ Search and filter conversations (all/flagged/normal)
- ‚úÖ Statistics dashboard (total, flagged, AI detections)
- ‚úÖ Keyword-based automatic flagging system
- ‚úÖ Ban user functionality (integrates with existing ban system)
- ‚úÖ Mute user functionality (basic implementation with notifications)

### 2. **AI-Powered Detection** (BASIC)
- ‚úÖ Keyword matching for suspicious phrases:
  - "send first", "trust me", "promise"
  - "quick before", "another site", "free robux"
  - "outside of platform", payment methods (PayPal, CashApp, etc.)
  - "discord", "private message"
- ‚úÖ Automatic flagging of conversations with banned users
- ‚úÖ Visual indicators for flagged messages and conversations

## üöß Recommended Enhancements

### 1. **Database Schema Updates** (HIGH PRIORITY)

Add muting capabilities to the User model:

```prisma
model User {
  // ... existing fields ...
  
  // Moderation fields
  isMuted     Boolean   @default(false)
  mutedUntil  DateTime? // null = permanent mute, date = temporary mute
  mutedReason String?   // reason for muting
  muteHistory Json?     // array of { mutedAt, mutedBy, reason, duration }
  
  // ... existing relations ...
}
```

**Migration command:**
```bash
npx prisma migrate dev --name add_user_muting_fields
```

### 2. **Advanced AI Detection** (MEDIUM PRIORITY)

#### Option A: Pattern Recognition (No external service)
Add more sophisticated detection in `getChatConversations`:

```typescript
// Pattern detection for common scam tactics
const scamPatterns = [
  /(?:send|pay|give).*(?:first|before)/i,              // "send first", "pay before"
  /trust.*(?:me|bro|promise)/i,                        // "trust me bro"
  /(?:quick|fast|hurry).*(?:before|limited)/i,         // urgency tactics
  /(?:\d+)\s*(?:vouches?|reviews?|deals?)/i,           // fake social proof
  /(?:discord|telegram|whatsapp|outside)/i,            // off-platform communication
  /(?:refund|money\s*back).*(?:later|after|guarantee)/i, // refund promises
]

const hasScamPattern = scamPatterns.some(pattern => 
  pattern.test(message.content)
)
```

#### Option B: OpenAI Integration (Recommended for production)
Install OpenAI SDK:
```bash
pnpm add openai
```

Add environment variable:
```env
OPENAI_API_KEY=your_api_key_here
```

Create `lib/ai-moderation.ts`:
```typescript
import OpenAI from 'openai'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

export async function analyzeMessageForScam(message: string): Promise<{
  isScam: boolean
  confidence: number
  reason: string
}> {
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content: `You are a content moderation AI for a Roblox trading marketplace. 
          Analyze messages for scam attempts, harassment, or policy violations.
          Consider:
          - Requests to pay/send items first without escrow
          - Off-platform payment methods
          - Urgency tactics
          - Fake social proof
          - Threats or harassment
          
          Respond with JSON: { isScam: boolean, confidence: 0-1, reason: string }`
        },
        {
          role: "user",
          content: message
        }
      ],
      temperature: 0.2,
      response_format: { type: "json_object" }
    })
    
    const result = JSON.parse(response.choices[0].message.content || '{}')
    return result
  } catch (err) {
    console.error('AI moderation error:', err)
    return { isScam: false, confidence: 0, reason: 'Analysis failed' }
  }
}
```

### 3. **Message Enforcement** (HIGH PRIORITY)

Prevent muted users from sending messages:

Update `app/actions/messages.ts` - add to `sendMessage` function:

```typescript
export async function sendMessage(conversationId: string, content: string) {
  const session = await auth()
  if (!session?.user?.id) {
    return { success: false, error: "You must be logged in" }
  }
  
  // Check if user is muted
  const user = await prisma.user.findUnique({
    where: { id: session.user.id },
    select: { isMuted: true, mutedUntil: true }
  })
  
  if (user?.isMuted) {
    // Check if temporary mute has expired
    if (user.mutedUntil && new Date() > user.mutedUntil) {
      // Unmute user
      await prisma.user.update({
        where: { id: session.user.id },
        data: { isMuted: false, mutedUntil: null }
      })
    } else {
      const muteMsg = user.mutedUntil 
        ? `You are muted until ${user.mutedUntil.toLocaleString()}`
        : "You are permanently muted"
      return { success: false, error: muteMsg }
    }
  }
  
  // ... rest of sendMessage logic
}
```

### 4. **Audit Logging** (MEDIUM PRIORITY)

Track all moderation actions:

```prisma
model ModerationLog {
  id        String   @id @default(cuid())
  adminId   String
  admin     User     @relation("ModerationAdmin", fields: [adminId], references: [id])
  
  targetId  String
  target    User     @relation("ModerationTarget", fields: [targetId], references: [id])
  
  action    String   // "MUTE" | "UNMUTE" | "BAN" | "UNBAN" | "WARN"
  reason    String
  duration  Int?     // hours, null = permanent
  
  conversationId String?  // context if action taken from chat monitoring
  messageId      String?  // specific message that triggered action
  
  createdAt DateTime @default(now())
  
  @@index([adminId])
  @@index([targetId])
  @@map("moderation_logs")
}
```

Update `muteUser` and `banUser` to create logs:

```typescript
await prisma.moderationLog.create({
  data: {
    adminId: session.user.id,
    targetId: userId,
    action: "MUTE",
    reason,
    duration,
    conversationId: context?.conversationId,
    messageId: context?.messageId,
  }
})
```

### 5. **Real-time Updates** (OPTIONAL)

Use Pusher or Socket.io for live conversation updates:

```bash
pnpm add pusher pusher-js
```

Set up Pusher:
```typescript
// lib/pusher.ts
import Pusher from 'pusher'

export const pusherServer = new Pusher({
  appId: process.env.PUSHER_APP_ID!,
  key: process.env.PUSHER_KEY!,
  secret: process.env.PUSHER_SECRET!,
  cluster: process.env.PUSHER_CLUSTER!,
})

// Trigger on new message
export async function notifyNewMessage(conversationId: string) {
  await pusherServer.trigger('admin-chat-monitoring', 'new-message', {
    conversationId,
    timestamp: new Date(),
  })
}
```

### 6. **Automated Actions** (ADVANCED)

Implement automatic bans for severe violations:

```typescript
// In getChatConversations or as a separate cron job
const severeKeywords = [
  'death threat', 'kill yourself', 'doxx', 'swat', 
  'child', 'minor', 'explicit content'
]

if (severeKeywords.some(kw => message.content.toLowerCase().includes(kw))) {
  // Auto-ban user
  await banUser(message.senderId, true, 'SYSTEM_AUTO_BAN')
  
  // Create escalated report
  await prisma.reportUser.create({
    data: {
      reporterId: 'SYSTEM',
      reportedId: message.senderId,
      reason: 'SEVERE_VIOLATION',
      details: 'Automatic ban triggered by severe policy violation',
      status: 'RESOLVED',
    }
  })
  
  // Notify admins
  await notifyAdmins({
    type: 'URGENT_BAN',
    userId: message.senderId,
    reason: 'Severe violation detected and auto-banned',
    conversationId: message.conversationId,
  })
}
```

### 7. **Statistics Enhancement** (LOW PRIORITY)

Track "Users Muted" count properly:

Update `getChatConversations` to include:

```typescript
const stats = {
  total: formattedConversations.length,
  flagged: formattedConversations.filter(c => c.flagged).length,
  aiDetections: formattedConversations.filter(c => 
    c.flagged && c.flagReason?.includes("Suspicious keywords")
  ).length,
  usersMuted: await prisma.user.count({
    where: { 
      isMuted: true,
      OR: [
        { mutedUntil: null }, // permanent mute
        { mutedUntil: { gt: new Date() } } // active temporary mute
      ]
    }
  })
}
```

### 8. **Export & Reporting** (OPTIONAL)

Add ability to export flagged conversations:

```typescript
export async function exportFlaggedConversations(
  startDate: Date,
  endDate: Date
): Promise<{ success: boolean; csvData?: string; error?: string }> {
  // Query flagged conversations
  // Format as CSV
  // Return download link
}
```

## üéØ Priority Implementation Order

1. **‚úÖ COMPLETED**: Basic chat monitoring with real data
2. **HIGH**: Database schema update for muting (15 min)
3. **HIGH**: Message send prevention for muted users (30 min)
4. **MEDIUM**: Enhanced pattern recognition (1 hour)
5. **MEDIUM**: Audit logging for accountability (1 hour)
6. **OPTIONAL**: OpenAI integration (~2 hours)
7. **OPTIONAL**: Real-time updates (~3 hours)
8. **OPTIONAL**: Auto-ban for severe violations (1 hour)

## üìä Current System Capabilities

‚úÖ **Working Now:**
- View all conversations with participants
- See full message history
- Search users in conversations
- Filter by flagged status
- Automatic keyword detection
- Manual ban/mute actions
- Toast notifications for admin actions
- Statistics dashboard

‚ö†Ô∏è **Limitations:**
- Mute doesn't actually prevent sending (needs schema update)
- No AI-powered analysis (only keyword matching)
- No audit trail for moderation actions
- No real-time updates (manual refresh needed)
- No bulk moderation actions

## üîß Quick Setup Steps

1. **Update schema** (copy from section 1 above)
2. **Run migration**: `npx prisma migrate dev --name add_user_muting`
3. **Update sendMessage** function to check mute status
4. **Deploy and test**

The chat monitoring system is now functional with real data and ready for production use with basic AI detection. Advanced features can be added incrementally based on platform needs.
